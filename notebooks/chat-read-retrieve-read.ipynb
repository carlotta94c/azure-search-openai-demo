{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "# Replace these with your own values, either in environment variables or directly here\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\") or \"mystorageaccount\"\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\") or \"content\"\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\") or \"gptkb\"\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\") or \"gptkbindex\"\n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\") or \"myopenai\"\n",
    "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\") or \"davinci\"\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") or \"chat\"\n",
    "\n",
    "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\") or \"content\"\n",
    "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\") or \"category\"\n",
    "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\") or \"sourcepage\"\n",
    "\n",
    "# Use the current user identity to authenticate with Azure OpenAI, Cognitive Search and Blob Storage (no secrets needed, \n",
    "# just use 'az login' locally, and managed identity when deployed on Azure). If you need to use keys, use separate AzureKeyCredential instances with the \n",
    "# keys for each service\n",
    "azure_credential = DefaultAzureCredential()\n",
    "\n",
    "# Used by the OpenAI SDK\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable instead\n",
    "openai.api_type = \"azure_ad\"\n",
    "openai.api_key = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=azure_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT uses a particular set of tokens to indicate turns in conversations\n",
    "prompt_prefix = \"\"\"<|im_start|>system\n",
    "L'assistente aiuta gli impiegati dell'azienda Contoso con le loro domande relative alla struttura dell'azienda e ai suoi piani per garantire la sicurezza e la protezione di dati e servizi.\n",
    "Rispondi SOLO con i fatti elencati nella lista di risorse sottostante e SOLO in lingua ITALIANA. Se non ci sono abbastanza informazioni nelle risorse sotto riportate, rispondi che non sai. Non generare risposte che non usano le risorse sotto elencate. Se ti può aiutare chiedere una domanda chiarificativa all'utente, ponigliela. \n",
    "Ogni fonte ha un nome seguito da due punti e l'informazione stessa. Includi sempre il nome della fonte per ogni fatto usato nella risposta. Usa le parentesi quadre per referenziare la fonte, ad esempio [info1.txt]. Non combinare più risorse, elenca ogni fonte in maniera separata, ad esempio [info1.txt][info2.pdf].\n",
    "Sources:\n",
    "{sources}\n",
    "\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "turn_prefix = \"\"\"\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "turn_suffix = \"\"\"\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompt_history = turn_prefix\n",
    "\n",
    "history = []\n",
    "\n",
    "summary_prompt_template = \"\"\"Sotto è disponibile un riassunto della conversazione corrente, e una nuova domanda posta dall'utente a cui deve essere data una risposta, cercando all'interno della base dati. Genera una query di ricerca basata sul contesto della conversazione e la nuova domanda. I nomi delle fonti non sono delle buone chiavi di ricerca da includere nella query di ricerca.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"Dov'è la sede principale di Contoso?\"\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "if len(history) > 0:\n",
    "    completion = openai.Completion.create(\n",
    "        engine=AZURE_OPENAI_GPT_DEPLOYMENT,\n",
    "        prompt=summary_prompt_template.format(summary=\"\\n\".join(history), question=user_input),\n",
    "        temperature=0.7,\n",
    "        max_tokens=32,\n",
    "        stop=[\"\\n\"])\n",
    "    search = completion.choices[0].text\n",
    "else:\n",
    "    search = user_input\n",
    "\n",
    "# Alternatively simply use search_client.search(q, top=3) if not using semantic search\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "r = search_client.search(search, \n",
    "                         filter=filter,\n",
    "                         query_type=QueryType.SEMANTIC, \n",
    "                         query_language=\"en-us\", \n",
    "                         query_speller=\"lexicon\", \n",
    "                         semantic_configuration_name=\"default\", \n",
    "                         top=3)\n",
    "results = [doc[KB_FIELDS_SOURCEPAGE] + \": \" + doc[KB_FIELDS_CONTENT].replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r]\n",
    "content = \"\\n\".join(results)\n",
    "\n",
    "prompt = prompt_prefix.format(sources=content) + prompt_history + user_input + turn_suffix\n",
    "\n",
    "completion = openai.Completion.create(\n",
    "    engine=AZURE_OPENAI_CHATGPT_DEPLOYMENT, \n",
    "    prompt=prompt, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024,\n",
    "    stop=[\"<|im_end|>\", \"<|im_start|>\"])\n",
    "\n",
    "prompt_history += user_input + turn_suffix + completion.choices[0].text + \"\\n<|im_end|>\" + turn_prefix\n",
    "history.append(\"user: \" + user_input)\n",
    "history.append(\"assistant: \" + completion.choices[0].text)\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "print(\"\\n-------------------\\nPrompt:\\n\" + prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
